





import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score





# Loading the Dataset
diabetes_dataset = pd.read_csv('data/diabetes.csv')


diabetes_dataset.head() # printing the first 5 rows in the dataset


# number of rows and columns in this dataset
diabetes_dataset.shape


diabetes_dataset.describe()


diabetes_dataset['Outcome'].value_counts()





diabetes_dataset.groupby('Outcome').mean()


X = diabetes_dataset.drop(columns = 'Outcome', axis = 1)
y = diabetes_dataset['Outcome']





scaler = StandardScaler() # Create a Standardization function


scaler.fit(X) # Fit the inconsistent data in the function


standardized_data = scaler.transform(X) # Transforms the data in a standardized one with better ranges eg 1-10 will be 0-1


# No need to write 'y' twice this is here so I can remember
X = standardized_data
y = diabetes_dataset['Outcome'] 





X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 2)


print(X.shape, X_train.shape, X_test.shape)
print(y.shape, y_train.shape, y_test.shape)





classifier = svm.SVC(kernel = 'linear')


# Training the SVMC (Support Vector Machine Classifier)
classifier.fit(X_train, y_train)





# Accuracy score of the Training Data
X_train_accuracy = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_accuracy, y_train)
print("Accuracy Score of Training Data:", training_data_accuracy)


# Accuracy score of the Test data
X_test_accuracy = classifier.predict(X_test)
test_data_accuracy = accuracy_score(X_test_accuracy, y_test)
print("Accuracy Score of Test Data:", test_data_accuracy)





input_data = (6,148,72,35,0,33.6,0.627,50) # Data of a diabetic Patient

# Change the Input data to NumPy Array
input_data_as_numpy_array = np.asarray(input_data)

# Reshape the data as we are predicting for 1 instance or else the model will expect all the rows that it was trainied on
# in this case 768 data so to tell model that only predict for this 1 instance.
reshaped_input_data = input_data_as_numpy_array.reshape(1, -1)

# Standardize this data for obvious reasons because the data it was trained on was standardized
std_data = scaler.transform(reshaped_input_data)

# Prediction
prediction = classifier.predict(std_data)

if (prediction[0] == 1):
    print("Patient has Diabetes")
else:
    print("Patient is Healthy")


# The warning above is happening because the data is in numpy and standardization requires Column names
# the reason is because the dataset has columns it is not an issue just a warning but to fix it 
# we can use pandas dataframes instead of numpy to solve this issue

input_data = (10,168,74,0,0,38,0.537,34) #Data of a Diabetic Patient

# Define feature names
feature_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

# Convert input data to DataFrame
input_df = pd.DataFrame([input_data], columns=feature_names)

# Standardize the data
std_data = scaler.transform(input_df)

# Make prediction
prediction = classifier.predict(std_data)

if (prediction[0] == 1):
    print("Patient has Diabetes")
else:
    print("Patient is Healthy")



print("")
